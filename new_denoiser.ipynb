{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "import os\n",
    "import argparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import wandb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings and gnns\n",
    "\n",
    "class GaussianEmbedding(nn.Module):\n",
    "    def __init__(self, num_terms, num_channels):\n",
    "        super(GaussianEmbedding, self).__init__()\n",
    "        self.num_terms = num_terms\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.h = nn.Parameter(torch.randn(num_terms + 1, num_channels))\n",
    "        nn.init.xavier_uniform_(self.h)\n",
    "\n",
    "    def forward(self, A):\n",
    "        batch_size, num_nodes, _ = A.shape\n",
    "        Y_hat = torch.zeros(batch_size, num_nodes, self.num_channels, device=A.device)\n",
    "        for c in range(self.num_channels):\n",
    "            result = self.h[0, c] * torch.eye(num_nodes, device=A.device).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            for i in range(1, self.num_terms + 1):\n",
    "                A_power_i = torch.matrix_power(A, i)\n",
    "                result += self.h[i, c] * A_power_i\n",
    "            Y_hat[..., c] = torch.diagonal(result, dim1=-2, dim2=-1)\n",
    "        return Y_hat\n",
    "\n",
    "class EigenEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EigenEmbedding, self).__init__()\n",
    "\n",
    "    def forward(self, A):\n",
    "        eigenvectors = []\n",
    "        for i in range(A.shape[0]):\n",
    "            _, V = torch.linalg.eigh(A[i])\n",
    "            eigenvectors.append(V)\n",
    "        return torch.stack(eigenvectors, dim=0)\n",
    "\n",
    "\n",
    "class GraphConvolutionLayer(nn.Module):\n",
    "    def __init__(self, num_terms, num_channels):\n",
    "        super(GraphConvolutionLayer, self).__init__()\n",
    "        self.num_terms = num_terms\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.H = nn.Parameter(torch.randn(num_terms + 1, num_channels, num_channels))\n",
    "        nn.init.xavier_uniform_(self.H)\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer_norm = nn.LayerNorm(num_channels)\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        Y_hat = X @ self.H[0] \n",
    "        for i in range(1, self.num_terms + 1):\n",
    "            A_power_i = torch.matrix_power(A, i)\n",
    "            Y_hat += torch.bmm(A_power_i, X) @ self.H[i]\n",
    "        Y_hat = self.layer_norm(Y_hat)\n",
    "        Y_hat = self.activation(Y_hat)\n",
    "        return Y_hat\n",
    "\n",
    "\n",
    "class NodeVarGraphConvolutionLayer(nn.Module):\n",
    "    def __init__(self, num_terms, num_channels, num_nodes):\n",
    "        super(NodeVarGraphConvolutionLayer, self).__init__()\n",
    "        self.num_terms = num_terms\n",
    "        self.num_channels = num_channels\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        self.h = nn.Parameter(torch.randn(num_terms + 1, num_channels, num_nodes))\n",
    "        nn.init.xavier_uniform_(self.h)\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer_norm = nn.LayerNorm(num_channels)\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        batch_size, num_nodes, num_channels_in = X.shape\n",
    "        Y_hat = torch.zeros(batch_size, num_nodes, self.num_channels, device=A.device)\n",
    "        for c in range(self.num_channels):\n",
    "            result = torch.zeros(batch_size, num_nodes, device=A.device)\n",
    "            h_diag = torch.diag_embed(self.h[0, c])\n",
    "            A_w = h_diag @ torch.eye(num_nodes, device=A.device).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            for ch in range(num_channels_in):\n",
    "                result += torch.bmm(A_w, X[..., ch].unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            for i in range(1, self.num_terms + 1):\n",
    "                A_power_i = torch.matrix_power(A, i)\n",
    "                h_diag = torch.diag_embed(self.h[i, c])\n",
    "                A_w = h_diag @ A_power_i\n",
    "                for ch in range(num_channels_in):\n",
    "                    result += torch.bmm(A_w, X[..., ch].unsqueeze(-1)).squeeze(-1)\n",
    "            Y_hat[..., c] = result\n",
    "        Y_hat = self.layer_norm(Y_hat)\n",
    "        Y_hat = self.activation(Y_hat)\n",
    "        return Y_hat\n",
    "\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, num_layers, num_terms=3, feature_dim_in=10, feature_dim_out=10):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # self.embedding_layer = GaussianEmbedding(num_terms, feature_dim)\n",
    "        self.embedding_layer = EigenEmbedding()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(GraphConvolutionLayer(num_terms, feature_dim_in))\n",
    "\n",
    "        self.out_x = nn.Linear(feature_dim_in, feature_dim_out)\n",
    "        self.out_y = nn.Linear(feature_dim_in, feature_dim_out)\n",
    "\n",
    "    def forward(self, A):\n",
    "        Z = self.embedding_layer(A)\n",
    "        for layer in self.layers:\n",
    "            Z = layer(A, Z)\n",
    "        X = self.out_x(Z)\n",
    "        Y = self.out_y(Z)\n",
    "        outer = torch.bmm(X, Y.transpose(1, 2))\n",
    "        A_pred = torch.sigmoid(outer)\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "class GNN_symmetric(nn.Module):\n",
    "    def __init__(self, num_layers, num_terms=3, feature_dim_in=10, feature_dim_out=10):\n",
    "        super(GNN_symmetric, self).__init__()\n",
    "\n",
    "        # self.embedding_layer = GaussianEmbedding(num_terms, feature_dim)\n",
    "        self.embedding_layer = EigenEmbedding()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(GraphConvolutionLayer(num_terms, feature_dim_in))\n",
    "\n",
    "        self.out_x = nn.Linear(feature_dim_in, feature_dim_out)\n",
    "\n",
    "\n",
    "    def forward(self, A):\n",
    "        Z = self.embedding_layer(A)\n",
    "        for layer in self.layers:\n",
    "            Z = layer(A, Z)\n",
    "        X = self.out_x(Z)\n",
    "\n",
    "        outer = torch.bmm(X, X.transpose(1, 2))\n",
    "        return torch.sigmoid(outer), X\n",
    "\n",
    "\n",
    "class NodeVarGNN(nn.Module):\n",
    "    def __init__(self, num_layers, num_terms=3, feature_dim=10):\n",
    "        super(NodeVarGNN, self).__init__()\n",
    "\n",
    "        # self.embedding_layer = GaussianEmbedding(num_terms, feature_dim)\n",
    "        self.embedding_layer = EigenEmbedding()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(NodeVarGraphConvolutionLayer(num_terms, feature_dim, feature_dim))\n",
    "\n",
    "        self.out_x = nn.Linear(feature_dim, feature_dim)\n",
    "        self.out_y = nn.Linear(feature_dim, feature_dim)\n",
    "\n",
    "    def forward(self, A):\n",
    "        Z = self.embedding_layer(A)\n",
    "        for layer in self.layers:\n",
    "            Z = layer(A, Z)\n",
    "        X = self.out_x(Z)\n",
    "        Y = self.out_y(Z)\n",
    "        outer = torch.bmm(X, Y.transpose(1, 2))\n",
    "        return torch.sigmoid(outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention layers\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module as described in 'Attention Is All You Need' paper.\n",
    "    \n",
    "    This implementation supports masked attention and different input/output dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, d_k=None, d_v=None, dropout=0.0, bias=False):\n",
    "        \"\"\"\n",
    "        Initialize the Multi-Head Attention module.\n",
    "        \n",
    "        Parameters:\n",
    "        - d_model: Model dimension (input and output dimension)\n",
    "        - num_heads: Number of attention heads\n",
    "        - d_k: Dimension of keys (default: d_model // num_heads)\n",
    "        - d_v: Dimension of values (default: d_model // num_heads)\n",
    "        - dropout: Dropout probability\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # If d_k and d_v are not specified, set them to d_model // num_heads\n",
    "        self.d_k = d_k if d_k is not None else d_model // num_heads\n",
    "        self.d_v = d_v if d_v is not None else d_model // num_heads\n",
    "        \n",
    "        # Linear projections for queries, keys, and values\n",
    "        self.W_q = nn.Linear(d_model, num_heads * self.d_k, bias=bias)\n",
    "        self.W_k = nn.Linear(d_model, num_heads * self.d_k, bias=bias)\n",
    "        self.W_v = nn.Linear(d_model, num_heads * self.d_v, bias=bias)\n",
    "        \n",
    "        # Output projection\n",
    "        self.W_o = nn.Linear(num_heads * self.d_v, d_model, bias=bias)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Layer normalization for the output\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Scaling factor for dot product attention\n",
    "        # self.scale = 1 / math.sqrt(self.d_k)\n",
    "        self.scale = 1\n",
    "\n",
    "        # Linear layer to combine attention scores from different heads\n",
    "        self.score_combination = nn.Linear(num_heads, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x, mask=None, residual=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the Multi-Head Attention module.\n",
    "        \n",
    "        Parameters:\n",
    "        - Q: Query tensor of shape (batch_size, seq_len_q, d_model)\n",
    "        - K: Key tensor of shape (batch_size, seq_len_k, d_model)\n",
    "        - V: Value tensor of shape (batch_size, seq_len_v, d_model)\n",
    "        - mask: Optional mask tensor of shape (batch_size, seq_len_q, seq_len_k)\n",
    "        - residual: Optional residual connection\n",
    "        \n",
    "        Returns:\n",
    "        - output: Output tensor of shape (batch_size, seq_len_q, d_model)\n",
    "        - attention: Attention weights of shape (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # If residual connection is not provided, use Q as residual\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "\n",
    "        # Linear projections and reshaping for multi-head attention\n",
    "        # Shape: (batch_size, seq_len, num_heads, d_*)\n",
    "\n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "\n",
    "        q = q.view(batch_size, -1, self.num_heads, self.d_k)\n",
    "        k = k.view(batch_size, -1, self.num_heads, self.d_k)\n",
    "        v = v.view(batch_size, -1, self.num_heads, self.d_v)\n",
    "\n",
    "\n",
    "\n",
    "        # Transpose to shape: (batch_size, num_heads, seq_len, d_*)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            # Add an extra dimension for the number of heads\n",
    "            if mask.dim() == 3:  # (batch_size, seq_len_q, seq_len_k)\n",
    "                mask = mask.unsqueeze(1)\n",
    "            \n",
    "            # Set masked positions to a large negative value before softmax\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Apply dropout to attention weights\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Calculate weighted sum of values\n",
    "        # (batch_size, num_heads, seq_len_q, d_v)\n",
    "        context = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Transpose and reshape to (batch_size, seq_len_q, num_heads * d_v)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_v)\n",
    "        \n",
    "        # Apply output projection\n",
    "        output = self.W_o(context)\n",
    "        \n",
    "        # Apply dropout and residual connection\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output + residual)\n",
    "\n",
    "        # Combine attention scores from different heads using learned weights\n",
    "        # Transpose scores to have heads dimension last: (batch_size, seq_len_q, seq_len_k, num_heads)\n",
    "        scores = scores.permute(0, 2, 3, 1)\n",
    "        # Apply linear combination: (batch_size, seq_len_q, seq_len_k, 1)\n",
    "        combined_scores = self.score_combination(scores)\n",
    "        # Remove last singleton dimension\n",
    "        combined_scores = combined_scores.squeeze(-1)\n",
    "        \n",
    "        return output, combined_scores\n",
    "\n",
    "\n",
    "class MultiLayerAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, d_k=None, d_v=None, dropout=0.0, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # If d_k and d_v are not specified, set them equal to d_model/num_heads\n",
    "        if d_k is None:\n",
    "            d_k = d_model // num_heads\n",
    "        if d_v is None:\n",
    "            d_v = d_model // num_heads\n",
    "            \n",
    "        # Create stack of attention layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiHeadAttention(d_model, num_heads=num_heads, d_k=d_k, d_v=d_v, dropout=dropout, bias=bias)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Keep track of attention scores from each layer\n",
    "        attention_scores = []\n",
    "        \n",
    "        # Pass through each attention layer sequentially\n",
    "        for layer in self.layers:\n",
    "\n",
    "            x, scores = layer(x, mask=mask)\n",
    "\n",
    "            attention_scores.append(scores)\n",
    "            \n",
    "        return x, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequential model combining embedding and denoising\n",
    "class SequentialDenoisingModel(nn.Module):\n",
    "    def __init__(self, embedding_model, denoising_model = None):\n",
    "        super(SequentialDenoisingModel, self).__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "        self.denoising_model = denoising_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First apply embedding model\n",
    "        X, Y = self.embedding_model(x)\n",
    "\n",
    "        Z = torch.cat([X, Y], dim=2)\n",
    "\n",
    "        if self.denoising_model is not None:\n",
    "            Z_pred = Z + self.denoising_model(Z)[0]\n",
    "        else:\n",
    "            Z_pred = Z\n",
    "\n",
    "        X_pred = Z_pred[:, :, 0:X.shape[2]]\n",
    "        Y_pred = Z_pred[:, :, X.shape[2]:]\n",
    "\n",
    "        A_recon = torch.sigmoid(torch.bmm(X_pred, Y_pred.transpose(1, 2)))                                  \n",
    "                                                                                                                                                                                                                                                                                                        \n",
    "        return A_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def generate_sbm_adjacency(block_sizes, p, q, rng=None):\n",
    "    \"\"\"\n",
    "    Generate an adjacency matrix for a stochastic block model with variable block sizes.\n",
    "\n",
    "    Parameters:\n",
    "    - block_sizes: List of sizes for each block.\n",
    "    - p: Probability of intra-block edges.\n",
    "    - q: Probability of inter-block edges.\n",
    "    - rng: Random number generator (optional).\n",
    "\n",
    "    Returns:\n",
    "    - Adjacency matrix as a numpy array.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    n_blocks = len(block_sizes)\n",
    "    n = sum(block_sizes)\n",
    "\n",
    "    # Initialize the adjacency matrix with zeros\n",
    "    \n",
    "    adj_matrix = np.zeros((n, n))\n",
    "\n",
    "    # Calculate the starting index of each block\n",
    "    block_starts = [0]\n",
    "    for i in range(n_blocks-1):\n",
    "        block_starts.append(block_starts[-1] + block_sizes[i])\n",
    "\n",
    "    for i in range(n_blocks):\n",
    "        for j in range(i, n_blocks):\n",
    "            density = p if i == j else q\n",
    "            block_start_i = block_starts[i]\n",
    "            block_end_i = block_start_i + block_sizes[i]\n",
    "            block_start_j = block_starts[j]\n",
    "            block_end_j = block_start_j + block_sizes[j]\n",
    "\n",
    "            # Generate random edges within or between blocks\n",
    "            block_i_size = block_sizes[i]\n",
    "            block_j_size = block_sizes[j]\n",
    "            adj_matrix[block_start_i:block_end_i, block_start_j:block_end_j] = (\n",
    "                rng.random((block_i_size, block_j_size)) < density\n",
    "            ).astype(int)\n",
    "\n",
    "            # Make the matrix symmetric (for undirected graphs)\n",
    "            if i != j:\n",
    "                adj_matrix[block_start_j:block_end_j, block_start_i:block_end_i] = (\n",
    "                    adj_matrix[block_start_i:block_end_i, block_start_j:block_end_j].T\n",
    "                )\n",
    "\n",
    "    return adj_matrix\n",
    "\n",
    "def add_digress_noise(A, p, rng=None):\n",
    "    \"\"\"\n",
    "    Add noise to an adjacency matrix by flipping edges with probability p.\n",
    "    \n",
    "    Parameters:\n",
    "    - adj_matrix: A 2D numpy array or tensor representing an adjacency matrix (0s and 1s)\n",
    "    - p: Probability of flipping each element (0 to 1, 1 becomes 0 and 0 becomes 1)\n",
    "    - rng: Random number generator (optional)\n",
    "    \n",
    "    Returns:\n",
    "    - Noisy adjacency matrix with some edges flipped\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    # Create a copy of the original matrix to avoid modifying it\n",
    "    A_noisy = A\n",
    "    \n",
    "    # Generate random values for each element\n",
    "    random_values = torch.rand_like(torch.tensor(A))\n",
    "    \n",
    "    # Create a mask for elements to flip (where random value < p)\n",
    "    flip_mask = random_values < p\n",
    "    \n",
    "    # Flip the elements where the mask is True (using XOR operation)\n",
    "    # XOR with 1 flips 0→1 and 1→0\n",
    "    A_noisy = torch.where(flip_mask, 1 - torch.tensor(A), torch.tensor(A))\n",
    "    \n",
    "    l, V = torch.linalg.eigh(A_noisy)\n",
    "\n",
    "    return torch.tensor(A_noisy, dtype=torch.float32), torch.tensor(V, dtype=torch.float32), torch.tensor(l, dtype=torch.float32)\n",
    "\n",
    "\n",
    "#Functions\n",
    "def generate_block_sizes(n, min_blocks=2, max_blocks=4, min_size=2, max_size=15):\n",
    "    # Example usage:\n",
    "    # n is the number of nodes\n",
    "    # n = 20\n",
    "    # partitions = generate_block_sizes(n)\n",
    "    # print(f\"Valid block size partitions for n={n}:\")\n",
    "    # for p in partitions:\n",
    "    #     print(p)\n",
    "    valid_partitions = []\n",
    "    \n",
    "    # Try different numbers of blocks\n",
    "    for num_blocks in range(min_blocks, max_blocks + 1):\n",
    "        def generate_partitions(remaining, blocks_left, current_partition):\n",
    "            # Base cases\n",
    "            if blocks_left == 0:\n",
    "                if remaining == 0:\n",
    "                    valid_partitions.append(current_partition[:])\n",
    "                return\n",
    "            \n",
    "            # Try different sizes for current block\n",
    "            start = max(min_size, remaining - (blocks_left-1)*max_size)\n",
    "            end = min(max_size, remaining - (blocks_left-1)*min_size) + 1\n",
    "            \n",
    "            for size in range(start, end):\n",
    "                if size <= remaining:\n",
    "                    current_partition.append(size)\n",
    "                    generate_partitions(remaining - size, blocks_left - 1, current_partition)\n",
    "                    current_partition.pop()\n",
    "        \n",
    "        generate_partitions(n, num_blocks, [])\n",
    "    \n",
    "    return valid_partitions\n",
    "\n",
    "class PermutedAdjacencyDataset(Dataset):\n",
    "    def __init__(self, adjacency_matrices, num_samples):\n",
    "        self.adjacency_matrices = adjacency_matrices\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Randomly choose between A_1 and A_2\n",
    "        matrix_idx = torch.randint(0, len(self.adjacency_matrices), (1,)).item()\n",
    "        adjacency_matrix = self.adjacency_matrices[matrix_idx]\n",
    "        \n",
    "        # Generate random permutation\n",
    "        permuted_indices = torch.randperm(adjacency_matrix.size(0))\n",
    "        A_permuted = adjacency_matrix[permuted_indices, :][:, permuted_indices]\n",
    "        return A_permuted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "#hyperparameters\n",
    "#######################################\n",
    "use_wandb = False\n",
    "\n",
    "#number of nodes\n",
    "n = 20\n",
    "\n",
    "use_transformer = True\n",
    "\n",
    "#GNN parameters\n",
    "gnn_num_layers = 2\n",
    "gnn_num_terms = 2\n",
    "gnn_feature_dim_in = 20\n",
    "gnn_feature_dim_out = 5 #this is the low dimensional embedding dimension\n",
    "\n",
    "#transformer parameters\n",
    "transformer_num_layers = 4\n",
    "transformer_num_heads = 4\n",
    "transformer_d_k = 10\n",
    "transformer_d_v = 10\n",
    "\n",
    "loss_type = \"BCE\" #loss criteria: either \"MSE\" or \"BCE\"\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "noise_levels = [0.005, 0.02, 0.05, 0.1, 0.25, 0.4, 0.5]\n",
    "\n",
    "num_epochs = 200\n",
    "test_epochs = 10\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#gives all possible partitions of n into 2-4 blocks\n",
    "partitions = generate_block_sizes(n)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sample 10 partitions for training and 10 for test\n",
    "train_partitions = random.sample(partitions, 10)\n",
    "test_partitions = random.sample([p for p in partitions if p not in train_partitions], 10)\n",
    "\n",
    "As_train = []\n",
    "As_test = []\n",
    "\n",
    "p_intra = 1.0\n",
    "q_inter = 0.0\n",
    "\n",
    "for p in train_partitions:\n",
    "    A = generate_sbm_adjacency(p, p_intra, q_inter)\n",
    "    A = torch.tensor(A)\n",
    "    As_train.append(A)\n",
    "\n",
    "for p in test_partitions:\n",
    "    A = generate_sbm_adjacency(p, p_intra, q_inter)\n",
    "    A = torch.tensor(A)\n",
    "    As_test.append(A)\n",
    "\n",
    "print(\"\\nTraining partitions:\")\n",
    "for p in train_partitions:\n",
    "    print(p)\n",
    "    \n",
    "print(\"\\nTest partitions:\") \n",
    "for p in test_partitions:\n",
    "    print(p)\n",
    "\n",
    "\n",
    "num_samples = 1000  # Define the number of samples you want\n",
    "train_dataset = PermutedAdjacencyDataset(As_train, num_samples)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = PermutedAdjacencyDataset(As_test, num_samples)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(As_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training partitions:\n",
      "[12, 2, 6]\n",
      "[3, 3, 14]\n",
      "[3, 8, 7, 2]\n",
      "[3, 4, 10, 3]\n",
      "[3, 2, 11, 4]\n",
      "[2, 3, 3, 12]\n",
      "[10, 5, 5]\n",
      "[10, 4, 3, 3]\n",
      "[8, 7, 5]\n",
      "[6, 3, 7, 4]\n",
      "\n",
      "Test partitions:\n",
      "[3, 11, 6]\n",
      "[3, 9, 8]\n",
      "[9, 6, 5]\n",
      "[3, 2, 12, 3]\n",
      "[3, 4, 4, 9]\n",
      "[8, 8, 2, 2]\n",
      "[3, 6, 11]\n",
      "[2, 10, 6, 2]\n",
      "[11, 3, 3, 3]\n",
      "[6, 4, 5, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   0%|                                                                                                                                                                           | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_1680612/4112231906.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  random_values = torch.rand_like(torch.tensor(A))\n",
      "/tmp/ipykernel_1680612/4112231906.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A_noisy = torch.where(flip_mask, 1 - torch.tensor(A), torch.tensor(A))\n",
      "/tmp/ipykernel_1680612/4112231906.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(A_noisy, dtype=torch.float32), torch.tensor(V, dtype=torch.float32), torch.tensor(l, dtype=torch.float32)\n",
      "Training epochs:  47%|████████████████████████████████████████████████████████████████████████████▏                                                                                     | 94/200 [00:40<00:44,  2.41it/s]"
     ]
    }
   ],
   "source": [
    "if use_wandb:\n",
    "    wandb.init(project=\"graph-denoising\", name=\"training_run\")\n",
    "\n",
    "\n",
    "\n",
    "model_embedding = GNN(num_layers=gnn_num_layers, num_terms=gnn_num_terms, feature_dim_in=gnn_feature_dim_in, feature_dim_out=gnn_feature_dim_out)\n",
    "model_embedding = model_embedding.double()\n",
    "\n",
    "\n",
    "\n",
    "model_denoiser = MultiLayerAttention(2*gnn_feature_dim_out, num_heads = transformer_num_heads, d_k = transformer_d_k, d_v = transformer_d_v, num_layers = transformer_num_layers, bias = True)\n",
    "model_denoiser.double()\n",
    "\n",
    "\n",
    "\n",
    "# Create combined sequential model\n",
    "if use_transformer == True:\n",
    "    model = SequentialDenoisingModel(model_embedding, model_denoiser)\n",
    "else:\n",
    "    model = SequentialDenoisingModel(model_embedding, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Log model hyperparameters if using wandb\n",
    "if use_wandb:\n",
    "    wandb.config.update({\n",
    "        \"gnn_num_layers\": gnn_num_layers,\n",
    "        \"gnn_num_terms\": gnn_num_terms,\n",
    "        \"gnn_feature_dim_in\": gnn_feature_dim_in,\n",
    "        \"gnn_feature_dim_out\": gnn_feature_dim_out,\n",
    "        \"transformer_num_layers\": transformer_num_layers,\n",
    "        \"transformer_num_heads\": transformer_num_heads,\n",
    "        \"transformer_d_k\": transformer_d_k,\n",
    "        \"transformer_d_v\": transformer_d_v,\n",
    "        \"loss_type\": loss_type,\n",
    "        \"use_transformer\": use_transformer,\n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "    })\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2)\n",
    "\n",
    "if loss_type == \"MSE\":  \n",
    "    criterion = nn.MSELoss()\n",
    "elif loss_type == \"BCE\":\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "#Training loop\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training epochs\"):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Sample random noise level for this batch\n",
    "        eps = np.random.choice(noise_levels)\n",
    "        batch_noisy = (add_digress_noise(batch, eps))[0]\n",
    "\n",
    "        batch_noisy = batch_noisy.double()\n",
    "        batch = batch.double()\n",
    "\n",
    "        output = model(batch_noisy)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, batch)\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Calculate average epoch loss\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    \n",
    "    #evaluate test error\n",
    "    test_loss = 0.0\n",
    "    num_batches = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            # Sample random noise level for this batch\n",
    "            eps = np.random.choice(noise_levels)\n",
    "            batch_noisy = (add_digress_noise(batch, eps))[0]\n",
    "\n",
    "            batch_noisy = batch_noisy.double()\n",
    "            batch = batch.double()\n",
    "\n",
    "            output = model(batch_noisy)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(output, batch)\n",
    "            test_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    \n",
    "    # Log metrics to wandb if enabled\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            \"train_loss\": avg_epoch_loss,\n",
    "            \"test_loss\": avg_test_loss,\n",
    "            \"noise_level\": eps,\n",
    "            \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "    \n",
    "    if (epoch) % test_epochs == 0:\n",
    "\n",
    "        \n",
    "        if use_wandb:\n",
    "            #evaluate train and test error per noise level\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_losses = []\n",
    "                test_losses = []\n",
    "                for eps in noise_levels:\n",
    "\n",
    "                    train_loss = 0.0\n",
    "                    test_loss = 0.0\n",
    "                    num_batches = 0\n",
    "\n",
    "                    for batch in train_dataloader:\n",
    "                        batch_noisy = (add_digress_noise(batch, eps))[0]\n",
    "                        batch_noisy = batch_noisy.double()\n",
    "                        batch = batch.double()\n",
    "                        output = model(batch_noisy)\n",
    "                        loss = criterion(output, batch)\n",
    "                        train_loss += loss.item()\n",
    "                        num_batches += 1\n",
    "\n",
    "                    train_losses.append(train_loss / num_batches)\n",
    "                    \n",
    "                    for batch in test_dataloader:\n",
    "                        batch_noisy = (add_digress_noise(batch, eps))[0]\n",
    "                        batch_noisy = batch_noisy.double()\n",
    "                        batch = batch.double()\n",
    "                        output = model(batch_noisy)\n",
    "                        loss = criterion(output, batch)\n",
    "                        test_loss += loss.item()\n",
    "                        num_batches += 1\n",
    "\n",
    "                    test_losses.append(test_loss / num_batches)\n",
    "\n",
    "                    wandb.log({\n",
    "                        \"eps_\" + str(eps) + \"_train_loss\": train_losses[-1],\n",
    "                        \"eps_\" + str(eps) + \"_test_loss\": test_losses[-1],\n",
    "                    })\n",
    "\n",
    "               \n",
    "\n",
    "                #visualize the results\n",
    "                eps_values = noise_levels\n",
    "                # Get reconstructions from the model for different noise levels\n",
    "                test_idx = np.random.randint(len(As_test))\n",
    "                train_idx = np.random.randint(len(As_train))\n",
    "                A_test = As_test[test_idx]\n",
    "                A_train = As_train[train_idx]\n",
    "\n",
    "                for j, A_orig in enumerate([A_test, A_train]):\n",
    "                    A_orig = A_orig.unsqueeze(0)\n",
    "\n",
    "                    fig_size = 4\n",
    "\n",
    "                    # Create a figure with subplots - 2 rows for noisy/recon pairs, 5 columns for noise levels\n",
    "                    fig, axes = plt.subplots(2, len(eps_values), figsize=(fig_size*len(eps_values), fig_size*2))\n",
    "\n",
    "                    # Plot pairs of noisy and reconstructed matrices for each noise level\n",
    "                    for i, eps in enumerate(eps_values):\n",
    "                        A_noisy = add_digress_noise(A_orig, eps)[0]\n",
    "                        with torch.no_grad():\n",
    "                            A_recon = model(A_noisy.double())[0]\n",
    "                        \n",
    "                        # Plot noisy matrix on top row\n",
    "                        im1 = axes[0,i].imshow(A_noisy.squeeze(0).numpy(), cmap='viridis')\n",
    "                        axes[0,i].set_title(f'Noisy (ε={eps})')\n",
    "                        \n",
    "                        # Plot reconstructed matrix below\n",
    "                        im2 = axes[1,i].imshow(A_recon.squeeze(0).numpy(), cmap='viridis')\n",
    "                        axes[1,i].set_title(f'Reconstructed')\n",
    "\n",
    "                    # Log visualization to wandb if enabled\n",
    "                    if j == 0:\n",
    "                        wandb.log({\"Test graph reconstruction\": wandb.Image(fig)})\n",
    "                    else:\n",
    "                        wandb.log({\"Train graph reconstruction\": wandb.Image(fig)})\n",
    "                    plt.close(fig)\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
