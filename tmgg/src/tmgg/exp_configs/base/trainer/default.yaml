# PyTorch Lightning trainer configuration
# All training configured in STEPS, not epochs

_target_: pytorch_lightning.Trainer

# Step-based training (no epochs)
max_steps: 10000              # Total training steps
max_epochs: -1                # Disable epoch-based termination

# Hardware
accelerator: "auto"
devices: "auto"
precision: 32

# Checkpointing
enable_checkpointing: true
default_root_dir: ${paths.output_dir}

# Logging
enable_progress_bar: true  # Custom StepProgressBar replaces default
log_every_n_steps: 1

# Validation in steps (integer = steps, float = epoch fraction)
val_check_interval: 1000      # Validate every 1000 steps
check_val_every_n_epoch: null # Disable epoch-based validation

# Early stopping and model checkpointing configured via callbacks config

# Gradient clipping
gradient_clip_val: 1.0
gradient_clip_algorithm: "norm"

# Reproducibility
deterministic: false
benchmark: true

# Debugging options (set to true for debugging)
fast_dev_run: false
overfit_batches: 0
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0
