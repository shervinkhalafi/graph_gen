# @package _global_
# Stage 4: Real-World Benchmarks
#
# Budget: 300 GPU-hours (future work)
# Goal: Validate on practical benchmark datasets from PyTorch Geometric
#
# Uses same optimizer settings as stage1_poc for fair comparison

defaults:
  - override /data: sbm_single_graph

# Stage identifier
stage: stage4_benchmarks

# Optimizer settings (matches stage1_poc)
learning_rate: 1e-2
weight_decay: 0.0
optimizer_type: adam
scheduler_config:
  type: none

# Model settings
model:
  k: 32

# Default noise levels (overridden in sweep)
noise_levels: [0.1]
eval_noise_levels: [0.1]

# --- Sweep metadata (used by coordinator when sweep=true) ---
_sweep_config:
  architectures:
    - models/spectral/filter_bank
    - models/spectral/self_attention
    - models/digress/digress_sbm_small
    - models/digress/digress_sbm_small_highlr
  datasets:
    - data/pyg_qm9
    - data/pyg_enzymes
    - data/pyg_proteins
  hyperparameter_space:
    learning_rate: [1e-3, 1e-2]
    model.k: [16, 32, 64]  # Variable graph sizes in PyG datasets
    noise_levels:
      - [0.01]
      - [0.05]
      - [0.1]
      - [0.2]
      - [0.3]
  num_trials: 6
  seeds: [1, 2, 3, 4, 5]
  timeout_seconds: 3600
  gpu_type: fast  # Larger graphs may need more VRAM

# Trigger condition:
# Run if Stage 3 validates cross-family generalization
trigger_conditions:
  stage3_cross_family_validation: true
