# Small DiGress model with high learning rate (adjacency mode)
#
# Same architecture as digress_sbm_small but with LR=1e-2 to compare
# against spectral models using the same optimizer settings.

_target_: tmgg.experiments.digress_denoising.lightning_module.DigressDenoisingLightningModule

# Experiment naming (used by base_config_digress.yaml)
digress_arch: "small_highlr"
digress_mode: "adj"
model_type: digress_small_highlr_adj

# High LR settings (matching spectral models in stage 1)
learning_rate: 1e-2
weight_decay: 0.0
optimizer_type: adam
amsgrad: false

# No scheduler (simpler optimization)
scheduler_config:
  type: none

# Loss
loss_type: "BCEWithLogits"

# Noise configuration (will be overridden by stage config)
noise_type: "digress"
noise_levels: [0.1]
seed: 42

# Small model for stage 1 (4 layers instead of official 8)
use_eigenvectors: false
n_layers: 4

hidden_dims:
  dx: 128
  de: 32
  dy: 128
  n_head: 4

# MLP hidden dims (scaled down proportionally from official 128/64/128)
hidden_mlp_dims:
  X: 64
  E: 32
  y: 64

output_dims:
  X: 0
  E: 1
  y: 0
