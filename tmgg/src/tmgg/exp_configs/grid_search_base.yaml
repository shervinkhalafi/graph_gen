# Base configuration for grid search experiments
# Use with Hydra multirun to sweep hyperparameters

defaults:
  - models/spectral/filter_bank@model  # Default model, will be overridden
  - data: grid_gaussian  # Default data config, will be overridden
  - base/trainer/default@trainer
  - base/logger/grid_wandb@logger
  - _self_

# Experiment identification
experiment_name: "grid_search_4k_params"
seed: 42
sanity_check: false

# Optimizer settings
learning_rate: 0.001  # Will be swept
weight_decay: 1e-4
optimizer_type: adamw

# Scheduler
scheduler_config:
  type: cosine_warmup
  warmup_fraction: 0.02
  decay_fraction: 0.8

# Loss function
loss_type: BCEWithLogits

# Noise configuration
noise_type: digress
noise_levels: [0.1]
eval_noise_levels: null
fixed_noise_seed: null

# Sync data module noise settings with model (prevents hparam conflict)
data:
  noise_type: ${noise_type}
  noise_levels: ${noise_levels}

# Override model parameters with data config values
model:
  noise_type: ${noise_type}
  noise_levels: ${noise_levels}
  seed: ${seed}
  learning_rate: ${learning_rate}

# Training configuration
trainer:
  max_epochs: 200
  check_val_every_n_epoch: 5
  log_every_n_steps: 10
  gradient_clip_val: 1.0
  enable_checkpointing: true
  enable_model_summary: true
  enable_progress_bar: true
  deterministic: true
  
  # Early stopping
  callbacks:
    - _target_: pytorch_lightning.callbacks.EarlyStopping
      monitor: "val/loss"
      patience: 20
      mode: "min"
      verbose: false
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: "val/loss"
      mode: "min"
      save_top_k: 3
      save_last: true
      filename: "${experiment_name}-epoch={epoch:02d}-val_loss={val/loss:.4f}"

# Evaluation settings
evaluation:
  visualization_epochs: 50  # Less frequent for grid search
  final_eval_noise_levels: ${data.noise_levels}

# Paths configuration
# - Local execution: Hydra resolves ${hydra:runtime.output_dir} automatically
# - Remote execution (Modal/Ray): prepare_config_for_remote() sets these to None,
#   then execute_task() resolves from TMGG_OUTPUT_BASE env var and run_id
paths:
  output_dir: ${hydra:runtime.output_dir}
  results_dir: ${paths.output_dir}/results

# Grid search parameters (to be swept)
noise_level: 0.1      # Will be overridden
model_name: "unknown" # Will be set based on model choice

# Hydra output directory (version-based for checkpoint resumption)
hydra:
  run:
    dir: outputs/v${tmgg_version:}/grid_search/${model_name}/${data.noise_type}/lr${learning_rate}/eps${noise_level}
  sweep:
    dir: outputs/sweeps/grid_search/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${model_name}_${data.noise_type}_lr${learning_rate}_eps${noise_level}